# Being On-Call

## What is On-Call ?

On-Call is an essential part of software ownership, as an engineer you are responsible for ensuring the reliability and availability of services and applications that your team has in production. 

There are clear positive consequences for the business in doing that. What is less visible, but just equally important, it is how this is very impactful for the team as well. Engineering is as much about building software as it is about maintaining it. It’s difficult to build scalable software if you are constantly worried about production outages. 

Software ownership is what allows us to make things better, you have to care and do the work. A key aspect for achieving that is to make the on-call experience pleasant with a defined framework in place which outlines goals, responsibilities and best practices.

## Which alerts ?

What you want is to align engineering "pain" with user "pain", by adopting thoughtful decision on when to page the person on-call. The type of alerts your system will produce should be categorized in three buckets:

* User pain alerts. These alerts are SLOs violations and end-to-end health check alerts, and they need attention immediately. Usually this type of alerts are defined as _blocker_ issues.
* Not user pain alerts. These are alerts coming from monitor the systems, which are meaningful, but not generate user pain. You want to take care of this during normal business hours. Usually this type of alerts are defined as _critical_ or _major_ issues.
* Not meaningful alert. Those are alerts which are not actionable, because are symptomatic alerts, i.e. CPU spikes. Replace them with SLOs or remove them.

You want to set a high bar for defining what are your user pain alerts, which will require defining and negotiating your SLOs with other stakeholders in the Company. When you have those in place, these are the alerts you want to wake up someone in the middle of the night and fix the issue. All others alerts should be managed during normal business hours, by being triaged, analyzed and resolved.


## On-Call Framework

Adopt a single source of page alerts, there are many incident management software available, pick one and stick with it (Pagerduty, OpsGenie, etc ..).

Establish a weekly on-call rotation which starts at noon on Monday, this will allow proper hands-off when all engineers are available to discuss and review the previous on-call week.

There should be two people on-call, a primary and a secondary. If the primary is unresponsive or unavailable when a support request comes in, then the secondary has the responsibility to make sure such request is not left unnoticed.

Each paging alerts should have a link to documentation describing the type of check in the alert and guidelines on how to debug the issue. 

You want to define a clear contract to communicate to the person on-call within your team and Company. If you are using slack (or any other form of chat system in your Company) create an alias/group for identifying the on-call group, for example `@platform-on-call`. The alias needs to be updated every time a new shift starts, and it is responsibility of the person finishing the previous shift to update the alias with the new engineers starting the new on-call week. There is an incentive for them doing that, since being off duty you do not want to receive or being pinged for new requests coming in. You can make use of reminders or building automation which notifies the on-call to update the alias.

## Setting the right expectations

Any person on-call need to receive clear expectations on what is requested from him or her during that week. For example:

* Being reachable 24x7 for blockers, routed by an automatic escalation system. 
* No roadmap items work. In fact, support tickets take priority over other tasks, and if there are no requests coming in, then this is the time to work on reducing tech debt.
* Keep attention on the channels where support requests are coming in, acknowledge and triage those.
* Keep attention on the system alerts generated by the observability tools in place.
* Owning follow-up tasks, to ensure that an escalation is fully resolved and does not become a re-occurring incident. For example, providing RCA and playbook.
* Preparing the agenda for the on-call retro for handing off on-call duty.
* If you are not available for the on-call shift is your responsibilities to let the team know and to find a substitute. Reach out to the team manager if you are not able to resolve this.

## Single point of contact

Sometimes high-pressured escalations can be chaotic. There could be many people involved or many systems at play, and it quickly becomes critical to keep track of what changes are in flight and who is doing what. You should adopt the philosophy that at all times a single point person will be in charge of the escalation response.

Handling an escalation doesn’t necessarily mean you resolve the root cause, or even have the expertise to do so. You are not expected to solve every problem, but you are expected to assess the issue, determine what the impact to the business, communicate externally and mitigate the request to the best of our ability. This is where team culture plays a key role in supporting each other and allow growing your own strengths, overcome challenges, and learn new skills. The experiences you will gain while on-call will teach you how to design and build better software, how to communicate clearly, and how to be a more empathetic teammate.

There will be cases where collaboration across teams is needed, in such cases reach to them using the proper channels you have available, for example `#team-<name>-support` channel and/or reach out to the engineering manager of the other team to get help. 

## Bringing new engineers into the rotation

It is not just adding people to the on-call rotation, you need to prepare them with training. 

* Document the infrastructure so that everyone has a clear view of the interoperability of all the components building the system.
* A new engineer should shadow the primary on-call to learn and get familiar with the process and the systems. It is up to the maturity of the team, and the skills of the new person added, that determinate for how long the shadowing will last. 

## On-Call Retro

Before on-call responsibility is passed to the next engineer in rotation, you want to have an on-call retro meeting to review issues that came up during the week, and to speak honestly and boldly about what we could have done better. This is the place where engineers advocate for critical infrastructure improvements, changes to existing processes, prioritize tech-debt, revisit SLOs and paging alerts.

